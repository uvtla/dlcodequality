{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f955f37-43fe-4b43-a66a-914f95450dc4",
   "metadata": {},
   "source": [
    "# 1. Importation des Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd84147-3048-465e-913d-57c61d4e2ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 19:44:14.823519: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-30 19:44:14.844052: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-30 19:44:14.844072: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-30 19:44:14.844609: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-30 19:44:14.848300: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-30 19:44:15.292487: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b6be0-aac7-4778-89c4-ff0489e15eaf",
   "metadata": {},
   "source": [
    "# 2.Fonctions d'augmentation des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4a85c7-c80f-4bcf-92db-4175269b5778",
   "metadata": {},
   "source": [
    "Préparer un ensemble de données pour l'entraînement en ayant un nombre équilibré d'exemples de qualité 'mauvaise' et 'bonne'.\r\n",
    "Augmenter l'ensemble de données pour améliorer la capacité de généralisation du modèle et pour empêcher le surajustement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27c7cae-5189-436b-93df-9cb8f9ca876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "BAD, GOOD = 0, 1\n",
    "\n",
    "def group_by(value_key_list, groups):\n",
    "    return [[value for value, key in value_key_list if key == group] for group in groups]\n",
    "\n",
    "def augment_dataset(dataset, factor = 10):\n",
    "    num_examples = len(dataset) * factor\n",
    "    bad_snippets, good_snippets = group_by(dataset, [BAD, GOOD])\n",
    "    half_examples = num_examples // 2\n",
    "    bad, good = [], []\n",
    "    for _ in range(half_examples):\n",
    "        # Generate 'bad' examples\n",
    "        num_bad = random.randint(1, 3)  # At least one bad snippet\n",
    "        num_good = random.randint(0, 2)  # Random number of good snippets\n",
    "        snippets = random.choices(bad_snippets, k=num_bad) + random.choices(good_snippets, k=num_good)\n",
    "        random.shuffle(snippets)\n",
    "        bad.append(\"\\n\".join(snippets))\n",
    "\n",
    "    for _ in range(half_examples, num_examples):\n",
    "        # Generate 'good' examples\n",
    "        num_snippets = random.randint(1, 4)\n",
    "        snippets = random.choices(good_snippets, k=num_snippets)\n",
    "        good.append(\"\\n\".join(snippets))\n",
    "\n",
    "    new_dataset = [[code, BAD] for code in bad] + [[code, GOOD] for code in good]\n",
    "\n",
    "    return dataset + new_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917f282-0b60-4ad1-967c-afc299053dff",
   "metadata": {},
   "source": [
    "# 3.Chargement des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6506231-8a94-49c2-a211-7f6f7747be88",
   "metadata": {},
   "source": [
    "Charger efficacement les données à partir d'un fichier de stockage externe dans la mémoire de travail pour le traitement ultérieur.\n",
    "Structurer les données de manière à ce qu'elles soient prêtes pour une utilisation directe dans les étapes d'entraînement\n",
    "et de validation du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c8ca101-2f32-456e-be76-f56ba40df3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path = 'GoodBadVariableNames_JS.json'\n",
    "data = pd.read_json(file_path)\n",
    "\n",
    "bad, good = data['bad'].tolist(), data['good'].tolist()\n",
    "dataset = [[code, BAD] for code in bad] + [[code, GOOD] for code in good]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77e4ce9-ace9-492b-83bf-6aeb3fb8c1c7",
   "metadata": {},
   "source": [
    "# 4.  Division et Augmentation des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd6d58-1e37-447e-ae1e-b4bf62842cad",
   "metadata": {},
   "source": [
    "Réaliser une division standard des données pour l'apprentissage supervisé, \n",
    "en s'assurant que le modèle est évalué sur des données non vues pendant l'entraînement.\n",
    "Augmenter les ensembles d'entraînement et de test pour éviter le surajustement et améliorer la généralisation du modèle.\n",
    "Préparer les ensembles de données de manière à ce que les caractéristiques et les étiquettes soient facilement accessibles pour l'entraînement et les évaluations du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638ecbd1-a092-4bf8-afcd-88bd2d8fb0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.1)\n",
    "train, test = [augment_dataset(dataset) for dataset in (train, test)]\n",
    "(X_train, y_train), (X_test, y_test) = ((list(x) for x in zip(*dataset)) for dataset in (train, test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31d65bd-2da2-40d7-bc13-273674706132",
   "metadata": {},
   "source": [
    "# 5. Préparation du Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2bc06-0805-4502-8f67-16323f88c447",
   "metadata": {},
   "source": [
    "Charger et préparer le tokenizer et le modèle pour le traitement des données textuelles spécifiques au code.\n",
    "Créer une structure de données personnalisée qui sera compatible avec les outils de PyTorch pour l'entraînement du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "772dd245-2f6e-4f34-828d-4baf5cb13e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/codebert-base\", num_labels=2)\n",
    "\n",
    "\n",
    "class CodeDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "encodings = tokenizer(X_train, truncation=True, padding=True)\n",
    "dataset = CodeDataset(encodings, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4877d65-874d-4d61-90e3-78aee1007ccb",
   "metadata": {},
   "source": [
    "# 6.Chargement  des feactures  du modèle  CodeBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e9542e-2264-4a6a-848e-1dc2a495ca88",
   "metadata": {},
   "source": [
    "Les embeddings sont un aspect fondamental du traitement du langage naturel et de l'apprentissage automatique, car ils permettent de représenter des textes en tant que points dans un espace vectoriel. Cela rend possible la comparaison, la classification, et d'autres formes d'analyse sur des données textuelles complexes. Dans le contexte de l'analyse de code, obtenir des embeddings de haute qualité est crucial pour comprendre la structure et le contenu du code, ce qui peut ensuite être appliqué pour détecter des motifs, des anomalies, ou évaluer la qualité du code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a309503f-d703-45b2-8e9e-3a2f437c282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "def get_codebert_embeddings(texts, tokenizer, model):\n",
    "    # Tokenize the input texts\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    # Get the embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # The embeddings can be taken from the last hidden state of the model\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    \n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e38fcdb-0bff-42ce-b2d0-d44cfe5bb754",
   "metadata": {},
   "source": [
    "# 7. La boucle d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e54db41-fac4-4963-98a8-1756f6e32b7e",
   "metadata": {},
   "source": [
    "Réaliser l'entraînement du modèle sur les données préparées en ajustant les poids pour minimiser la perte.\n",
    "Utiliser des paramètres d'entraînement standards pour l'ajustement fin d'un modèle pré-entraîné dans un cadre de classification de séquences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd497619-e556-4a7d-9b1b-dbff2cbd9a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 359/359 [36:18<00:00,  6.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define training parameters\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1):\n",
    "    for batch in tqdm(loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aefeaf-b4c0-46f8-a489-d0db6b4a9b91",
   "metadata": {},
   "source": [
    "# 8. Évaluation du Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1731846e-a094-4952-9dd0-0cd01c6d5493",
   "metadata": {},
   "source": [
    "Évaluer le modèle sur un ensemble de données de validation pour déterminer sa performance en termes de précision des prédictions\n",
    "precision_recall_fscore_support calcule la précision, le rappel, et le score F1 pour les prédictions binaires (bon ou mauvais code).\r\n",
    "accuracy_score calcule l'exactitude globale des prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d145499-464d-4436-bc1e-7db7a2494d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:45<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8432601880877743, Precision: 0.9426229508196722, Recall: 0.7278481012658228, F1: 0.8214285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "val_encodings = tokenizer(X_test, truncation=True, padding=True)\n",
    "val_dataset = CodeDataset(val_encodings, y_test)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader):\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            labels = batch['labels']\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions.extend(torch.argmax(logits, dim=1).tolist())\n",
    "            true_labels.extend(labels.tolist())\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Example evaluation after training\n",
    "accuracy, precision, recall, f1 = evaluate(model, val_loader)\n",
    "print(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e13f0a-c5f9-48bf-8e2c-1f5cba33a715",
   "metadata": {},
   "source": [
    "# Prédictions à partir du modèle sur un seul batch de données de validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e382d374-8ec6-4f74-8266-78e52a21404f",
   "metadata": {},
   "source": [
    "Réaliser une inférence rapide sur un petit ensemble de données pour vérifier le comportement du modèle ou pour des démonstrations.\r\n",
    "Fournir un moyen simple de tester le modèle avec des données réelles sans avoir à exécuter l'ensemble du processus d'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ce0fd6f-4cf8-41e5-97b7-8841bcf90c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(val_loader))\n",
    "input_ids = batch['input_ids']\n",
    "attention_mask = batch['attention_mask']\n",
    "outputs = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3c854-3ee1-4a77-8667-51efb41757be",
   "metadata": {},
   "source": [
    " Comment un nouvel exemple de code peut être préparé pour une telle inférence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e38104d-c771-4664-a5cd-0d257287c32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 10806, 3023, 5457, 204, 2]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(['var x = 4'], truncation=True, padding=True)['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218244bb-8030-4015-b13b-8bdce4e6824e",
   "metadata": {},
   "source": [
    "# 9. Un petit test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b956372a-4fc5-4459-baca-521dce6d03a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b4165b7-34b3-46dd-998f-e66fe5a90d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[ 3.3566, -3.5776]]), hidden_states=None, attentions=None)\n",
      "let s = new Student(); is: Bad Quality\n",
      "SequenceClassifierOutput(loss=None, logits=tensor([[-1.4207,  0.7625]]), hidden_states=None, attentions=None)\n",
      "let student = new Student(); is: Good Quality\n"
     ]
    }
   ],
   "source": [
    "def predict_code_quality(model, tokenizer, code_snippet):\n",
    "    # Tokenize the code snippet\n",
    "    inputs = tokenizer(code_snippet, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "    # Run the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        print(outputs)\n",
    "        bad, good = outputs.logits[0]\n",
    "    \n",
    "    # Interpret the output (0 for bad quality, 1 for good quality)\n",
    "    quality = \"Good Quality\" if good > bad else \"Bad Quality\"\n",
    "    return quality\n",
    "\n",
    "# Example usage\n",
    "for code_snippet in [\"let s = new Student();\", \"let student = new Student();\"]:\n",
    "    quality = predict_code_quality(model, tokenizer, code_snippet)\n",
    "    print(f\"{code_snippet} is: {quality}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547741d2-c505-4349-b9af-f401730f762c",
   "metadata": {},
   "source": [
    "# 10. Sauvgarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fc6d31e-77ed-426c-908e-bdedbd12bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'tester1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aec4ec-a7de-4645-9757-2ed5321e249a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
