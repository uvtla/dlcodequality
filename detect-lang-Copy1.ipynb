{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499ce49-6323-444b-ac95-9b5c876cf698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.chdir('dataset/Diff_Quality_Estimation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b5b800-b349-40bc-b749-654bd2df0905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ds import CodeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c775a5-40fd-4a6d-bfd8-a53e955cc97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from filenames import train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ccbf582-d789-4a23-94f4-332a328f7da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "device = torch.device('cuda')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/codebert-base\", num_labels=2).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bc41446-b0ea-4ae7-b33c-cf9dbf33ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cecce72f-77b3-46db-b185-b3a279fbd50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff00b2cb-93a4-4595-9904-1ca19c84cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = CodeDataset(train_files[:1], '-testjs', tokenizer, 512, lambda x: x[0], lambda x: [1, 0] if x[1] else [0, 1])\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e7671d7-8ac6-40c7-a91e-29adda94a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7778b7-d3ce-4748-a196-27a7ecc408b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac6941b-748a-4b42-b7f0-b1a471d55d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('lang-classifier2.pt'))\n",
    "optimizer.load_state_dict(torch.load('lang-optimizer2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29588084-30bb-4e34-8c0f-8f1415763646",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80190e96-1472-443b-b2dd-5598302d4739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2081/2081 [1:03:54<00:00,  1.84s/it]\n",
      "100%|██████████| 2077/2077 [1:02:53<00:00,  1.82s/it]\n",
      "100%|██████████| 2075/2075 [1:02:50<00:00,  1.82s/it]\n",
      "100%|██████████| 2076/2076 [1:02:49<00:00,  1.82s/it]\n",
      "100%|██████████| 2081/2081 [1:02:58<00:00,  1.82s/it]\n",
      "100%|██████████| 2077/2077 [1:02:50<00:00,  1.82s/it]\n",
      "100%|██████████| 2075/2075 [1:02:44<00:00,  1.81s/it]\n",
      "100%|██████████| 2076/2076 [1:02:42<00:00,  1.81s/it]\n",
      "100%|██████████| 2081/2081 [1:02:49<00:00,  1.81s/it]\n",
      "100%|██████████| 2077/2077 [1:02:41<00:00,  1.81s/it]\n",
      "100%|██████████| 2075/2075 [1:02:36<00:00,  1.81s/it]\n",
      "100%|██████████| 2076/2076 [1:02:37<00:00,  1.81s/it]\n",
      "100%|██████████| 2081/2081 [1:02:46<00:00,  1.81s/it]\n",
      "100%|██████████| 2077/2077 [1:02:38<00:00,  1.81s/it]\n",
      "100%|██████████| 2075/2075 [1:02:34<00:00,  1.81s/it]\n",
      "100%|██████████| 2076/2076 [1:02:36<00:00,  1.81s/it]\n",
      "100%|██████████| 2081/2081 [1:02:45<00:00,  1.81s/it]\n",
      "100%|██████████| 2077/2077 [1:02:37<00:00,  1.81s/it]\n",
      "100%|██████████| 2075/2075 [1:02:34<00:00,  1.81s/it]\n",
      "100%|██████████| 2076/2076 [1:02:35<00:00,  1.81s/it]\n",
      "100%|██████████| 2081/2081 [1:02:45<00:00,  1.81s/it]\n",
      "100%|██████████| 2077/2077 [1:02:38<00:00,  1.81s/it]\n",
      "100%|██████████| 2075/2075 [1:02:34<00:00,  1.81s/it]\n",
      "100%|██████████| 2076/2076 [1:02:36<00:00,  1.81s/it]\n",
      "100%|██████████| 2081/2081 [1:02:44<00:00,  1.81s/it]\n",
      "100%|██████████| 2077/2077 [1:02:37<00:00,  1.81s/it]\n",
      "100%|██████████| 2075/2075 [1:02:33<00:00,  1.81s/it]\n",
      "100%|██████████| 2076/2076 [1:02:34<00:00,  1.81s/it]\n",
      "100%|██████████| 2081/2081 [1:02:44<00:00,  1.81s/it]\n",
      "100%|██████████| 2077/2077 [1:02:37<00:00,  1.81s/it]\n",
      "100%|██████████| 2075/2075 [1:02:33<00:00,  1.81s/it]\n",
      "100%|██████████| 2076/2076 [1:02:36<00:00,  1.81s/it]\n",
      " 79%|███████▊  | 1636/2081 [49:38<14:20,  1.93s/it]"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for filename in train_files:\n",
    "        dataset = CodeDataset([filename], '-testjs', tokenizer, 512, lambda x: x[0], lambda x: [1, 0] if x[1] else [0, 1])\n",
    "        dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "        \n",
    "        for batch in tqdm(dataloader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "    \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1254bbb7-fc29-4502-8f86-acff3b1b814e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cacbdb2f-0864-4572-b1a9-1f686ad43c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'lang-classifier2.pt')\n",
    "torch.save(optimizer.state_dict(), 'lang-optimizer2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c3a5a-666c-43d3-a64d-bac163cf1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from filenames import all_files\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "N = 160  # Number of items you want in your DataLoader\n",
    "\n",
    "val_dataset = CodeDataset(train_files[0:1], '-testjs', tokenizer, 512, lambda x: x[0], lambda x: [1, 0] if x[1] else [0, 1])\n",
    "limited_dataset = Subset(val_dataset, indices=range(N))\n",
    "val_loader = DataLoader(limited_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels, list_logits = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "    \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            logits = outputs.logits\n",
    "            print(input_ids, attention_mask)\n",
    "            predictions.extend(torch.argmax(logits, dim=1).tolist())\n",
    "            true_labels.extend(torch.argmax(labels, dim=1).tolist())\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    return accuracy, precision, recall, f1, predictions, true_labels\n",
    "\n",
    "# Example evaluation after training\n",
    "accuracy, precision, recall, f1, predictions, true_labels = evaluate(model, val_loader)\n",
    "print(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "780793fc-2ef3-497e-9171-8741f699a0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d92e73a2-9e78-4a54-8641-5720ad8fcd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = next(iter(dataloader))\n",
    "batch2 = next(iter(dataloader))\n",
    "#model.classifier.out_proj.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaac3686-56dd-4d22-ad45-3585bc4b7292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 37815, 18851,  ...,     1,     1,     1],\n",
       "        [    0,  4684, 22565,  ...,     1,     1,     1],\n",
       "        [    0,  4684, 38650,  ...,  1437,  1437,     2],\n",
       "        ...,\n",
       "        [    0, 49453,   111,  ...,     1,     1,     1],\n",
       "        [    0, 41975, 11988,  ...,     1,     1,     1],\n",
       "        [    0, 37815, 18851,  ...,     4,  5330,     2]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch2['input_ids'].to(cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a9337cd-ac30-47ee-aa9c-1849ea6c048e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3412,  0.2680,  0.3021,  ..., -0.2898,  0.8585,  0.8295],\n",
       "         [-0.1310,  0.5211,  1.1932,  ..., -2.2609,  0.9663,  0.4517],\n",
       "         [-0.5610,  0.1916,  1.3016,  ..., -2.5255,  0.5054,  0.9198],\n",
       "         ...,\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718]],\n",
       "\n",
       "        [[-0.3412,  0.2680,  0.3021,  ..., -0.2898,  0.8585,  0.8295],\n",
       "         [-0.5919,  0.4964,  1.3286,  ..., -1.3175,  0.9040,  0.4439],\n",
       "         [-0.2158,  0.0730,  2.2302,  ..., -2.1365,  0.8708,  0.8628],\n",
       "         ...,\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718]],\n",
       "\n",
       "        [[-0.3412,  0.2680,  0.3021,  ..., -0.2898,  0.8585,  0.8295],\n",
       "         [-0.5919,  0.4964,  1.3286,  ..., -1.3175,  0.9040,  0.4439],\n",
       "         [-0.2077,  0.2025,  1.3160,  ..., -2.1641,  0.3990,  0.5502],\n",
       "         ...,\n",
       "         [-0.6674,  0.5860,  1.2565,  ..., -0.1668,  0.0153,  0.0590],\n",
       "         [-0.6093,  0.9819,  1.3168,  ..., -0.1754,  0.4408,  0.0183],\n",
       "         [-0.6336,  0.4416,  1.3082,  ..., -1.2342,  0.3718,  0.4671]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3412,  0.2680,  0.3021,  ..., -0.2898,  0.8585,  0.8295],\n",
       "         [-0.1339,  0.5359,  1.2362,  ..., -2.2525,  0.4802,  0.0998],\n",
       "         [-0.6312,  0.5451,  1.3419,  ..., -2.3410,  0.9562,  0.4756],\n",
       "         ...,\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718]],\n",
       "\n",
       "        [[-0.3412,  0.2680,  0.3021,  ..., -0.2898,  0.8585,  0.8295],\n",
       "         [-0.2838,  0.1636,  2.1342,  ..., -2.0813,  0.8615,  0.1632],\n",
       "         [-0.2251,  0.1898,  2.2986,  ..., -2.1835,  0.9185,  0.8824],\n",
       "         ...,\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718]],\n",
       "\n",
       "        [[-0.3412,  0.2680,  0.3021,  ..., -0.2898,  0.8585,  0.8295],\n",
       "         [-0.1310,  0.5211,  1.1932,  ..., -2.2609,  0.9663,  0.4517],\n",
       "         [-0.5610,  0.1916,  1.3016,  ..., -2.5255,  0.5054,  0.9198],\n",
       "         ...,\n",
       "         [-0.7103,  0.1752,  1.2431,  ..., -1.5559,  0.0111,  0.0674],\n",
       "         [-0.5961,  0.9798,  0.0407,  ..., -0.2106,  0.3567, -0.1392],\n",
       "         [-0.6336,  0.4416,  1.3082,  ..., -1.2342,  0.3718,  0.4671]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = batch2\n",
    "model.to(cpu).roberta.embeddings(batch2['input_ids'].to(cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb97b7-c4a2-4946-9169-f4dc0c68260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(cpu).roberta(batch1['input_ids'].to(cpu), attention_mask = batch1['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99e32154-6a52-4e9b-8321-bbed15b0c021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    0, 37815, 18851,  ...,     1,     1,     1],\n",
       "         [    0,  4684, 22565,  ...,     1,     1,     1],\n",
       "         [    0,  4684, 38650,  ...,  1437,  1437,     2],\n",
       "         ...,\n",
       "         [    0, 49453,   111,  ...,     1,     1,     1],\n",
       "         [    0, 41975, 11988,  ...,     1,     1,     1],\n",
       "         [    0, 37815, 18851,  ...,     4,  5330,     2]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch['input_ids'].to(cpu), batch['attention_mask'].to(cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfcd71e4-92f3-40e1-bce6-37b72bdda430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3412,  0.2680,  0.3021,  ..., -0.2898,  0.8585,  0.8295],\n",
       "         [-0.6888,  0.1610,  2.2540,  ..., -1.1899,  0.9799,  0.0969],\n",
       "         [-0.6100,  0.4691,  1.2676,  ..., -1.3877,  0.5095,  0.9338],\n",
       "         ...,\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718]],\n",
       "\n",
       "        [[-0.3412,  0.2680,  0.3021,  ..., -0.2898,  0.8585,  0.8295],\n",
       "         [-0.1364,  0.2028,  2.1119,  ..., -2.2385,  0.9318,  0.1240],\n",
       "         [-0.1204,  0.5067,  2.3155,  ..., -1.1716,  0.4899,  0.8391],\n",
       "         ...,\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718]],\n",
       "\n",
       "        [[-0.3412,  0.2680,  0.3021,  ..., -0.2898,  0.8585,  0.8295],\n",
       "         [-0.2499,  0.1800,  2.2900,  ..., -2.3449,  0.9070,  0.1200],\n",
       "         [-0.1707,  0.1716,  1.2525,  ..., -2.2842,  0.5169,  0.8729],\n",
       "         ...,\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3412,  0.2680,  0.3021,  ..., -0.2898,  0.8585,  0.8295],\n",
       "         [-0.5919,  0.4964,  1.3286,  ..., -1.3175,  0.9040,  0.4439],\n",
       "         [-0.2515,  0.1694,  1.2360,  ..., -2.1340,  0.5215,  0.5276],\n",
       "         ...,\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718]],\n",
       "\n",
       "        [[-0.3412,  0.2680,  0.3021,  ..., -0.2898,  0.8585,  0.8295],\n",
       "         [-0.1364,  0.2028,  2.1119,  ..., -2.2385,  0.9318,  0.1240],\n",
       "         [-0.1204,  0.5067,  2.3155,  ..., -1.1716,  0.4899,  0.8391],\n",
       "         ...,\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718]],\n",
       "\n",
       "        [[-0.3412,  0.2680,  0.3021,  ..., -0.2898,  0.8585,  0.8295],\n",
       "         [-0.5919,  0.4964,  1.3286,  ..., -1.3175,  0.9040,  0.4439],\n",
       "         [-0.2101,  0.1003,  2.2202,  ..., -1.2893,  0.9451,  0.8415],\n",
       "         ...,\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718],\n",
       "         [-0.4277,  0.3331,  1.7303,  ..., -1.6854,  0.2706,  0.2718]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = batch1\n",
    "model.to(cpu).roberta.embeddings(batch['input_ids'].to(cpu))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
